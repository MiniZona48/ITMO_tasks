{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Spark Machine Learning\n",
        "Модуль машинного обучения Spark предоставляет базовый набор инструментов ([документация](https://spark.apache.org/docs/latest/ml-guide.html)):\n",
        "* Алгоритмы классификации, регрессии, кластеризации, совместной фильтрации.\n",
        "* Методы работы с признаками.\n",
        "* Конвейеры (pipelines), описывающие основные стадии моделирования.\n",
        "* Сохранение и загрузка моделей и конвейеров.\n",
        "* Утилиты для линейной алгебры, статистики, обработки данных и др.\n",
        "<br/>\n",
        "\n",
        "Кроме того, Spark ML позволяет добавлять свои методы и реализовывать недостающие алгоритмы.\n",
        "\n"
      ],
      "metadata": {
        "id": "WKETiPoTf8Ua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Spark ML состоит из двух библиотек, отличающихся типом построения данных:\n",
        "* spark.ml – библиотека машинного обучения, основанная на DataFrame API;\n",
        "* spark.mllib – библиотека машинного обучения, основанная на RDD API.\n",
        "\n",
        "Начиная с версии 2.0 основной библиотекой является spark.ml, но spark.mllib содержит типы данных, используемые в spark.ml.\n",
        "\n"
      ],
      "metadata": {
        "id": "lj6cRalZliEC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "В качестве примера возмем задачу предсказания дней с низкой влажностью. Описание задачи и набор данных в задании.\n",
        "Это задача бинарной классификации. Необходимо построить модель, предсказывающую по различным погодным показателям, измеренным в утренние часы, будет ли в этот день низкая влажность или нет."
      ],
      "metadata": {
        "id": "_prsnTV_Gnsa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Подключаем google диск\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n73ZV9eqoBy5",
        "outputId": "700c656c-4e0d-4def-eaf0-d735a370b783"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/MyDrive/data/daily_weather.csv' # путь к данным на диске"
      ],
      "metadata": {
        "id": "doxAMb6X0DI7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "suCVbDdkhW0v",
        "outputId": "d2c95941-e8b2-4fc9-b96b-b85c0b0eadf7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.0.tar.gz (316.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.9/316.9 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.0-py2.py3-none-any.whl size=317425345 sha256=2e901d3a75a952f84c34dbac52e71a80ca680e843930e463a7289034784d3af2\n",
            "  Stored in directory: /root/.cache/pip/wheels/41/4e/10/c2cf2467f71c678cfc8a6b9ac9241e5e44a01940da8fbb17fc\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.0\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (10.0.1)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.10/dist-packages (from pyarrow) (1.23.5)\n"
          ]
        }
      ],
      "source": [
        "! pip install pyspark\n",
        "! pip install pyarrow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import DataFrameNaFunctions\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.classification import DecisionTreeClassifier\n",
        "from pyspark.ml.feature import Binarizer\n",
        "from pyspark.ml.feature import VectorAssembler, StringIndexer, VectorIndexer\n",
        "\n",
        "import os\n",
        "os.environ[\"PYARROW_IGNORE_TIMEZONE\"] = \"1\" # без этой строчки постоянно будет возникать предупреждение с просьбой установить эту переменную в значение 1"
      ],
      "metadata": {
        "id": "zD37jFEWiDrW"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Точкой входа в Spark-приложение для создания DataFrame является SparkSession, в котором определяются параметры конфигурации: название приложения, кластерный менеджер (т.е. каким образом подключиться — локально, к Kubernates или YARN и т.д.), количество выделяемых ядер и памяти. Пример инициализации может выглядеть так:\n",
        "```\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .config(\"spark.ui.enabled\", \"true\") \\\n",
        "    .config(\"spark.driver.memory\", \"8g\") \\\n",
        "    .config(\"spark.executor.instances\", \"4\") \\\n",
        "    .config(\"spark.executor.cores\", \"4\") \\\n",
        "    .config(\"spark.executor.memory\", \"6g\") \\\n",
        "    .config(\"spark.executor.memoryOverhead\", \"200m\") \\\n",
        "    .config(\"spark.dynamicAllocation.enabled\", \"true\") \\\n",
        "    .config(\"spark.dynamicAllocation.shuffleTracking.enabled\", \"true\") \\\n",
        "    .config(\"spark.sql.parquet.compression.codec\", \"snappy\") \\\n",
        "    .config(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\") \\\n",
        "    .getOrCreate()\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "RX7SrkHdiARO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Создание сессии"
      ],
      "metadata": {
        "id": "QtAesYi_pkdy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.getOrCreate()\n",
        "spark.conf.set(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\")\n",
        "spark"
      ],
      "metadata": {
        "id": "soCmdJBdh8dm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "65a68115-a146-4e50-d97a-08edc72d6c89"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7d11895bda80>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://6349c69fe79d:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.0</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Загрузка данных в Spark DataFrame\n",
        "df = spark.read.csv('daily_weather.csv', header=True, inferSchema=True)\n",
        "# аргумент inferSchema указывает на вывод типа данных"
      ],
      "metadata": {
        "id": "xg-nWkKUjIE5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для понимания данных полезно знать кого типа колонки присутствуют в наборе данных. Чаще всего для вывода схемы DataFrame используется метод `printSchema`:"
      ],
      "metadata": {
        "id": "F14Ku3_vJtKc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5aNPZDjkKAYD",
        "outputId": "8401bc0b-9135-47a9-ba1a-9f61c59ce38c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- number: integer (nullable = true)\n",
            " |-- air_pressure_9am: double (nullable = true)\n",
            " |-- air_temp_9am: double (nullable = true)\n",
            " |-- avg_wind_direction_9am: double (nullable = true)\n",
            " |-- avg_wind_speed_9am: double (nullable = true)\n",
            " |-- max_wind_direction_9am: double (nullable = true)\n",
            " |-- max_wind_speed_9am: double (nullable = true)\n",
            " |-- rain_accumulation_9am: double (nullable = true)\n",
            " |-- rain_duration_9am: double (nullable = true)\n",
            " |-- relative_humidity_9am: double (nullable = true)\n",
            " |-- relative_humidity_3pm: double (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Сводная статистика\n",
        "df.describe().toPandas().transpose()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "H5fn7dSq8L6u",
        "outputId": "6d967c91-3467-424f-bed0-3654c02d8c18"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                            0                    1                   2  \\\n",
              "summary                 count                 mean              stddev   \n",
              "number                   1095                547.0  316.24357700987383   \n",
              "air_pressure_9am         1092    918.8825513138094   3.184161180386833   \n",
              "air_temp_9am             1090    64.93300141287072  11.175514003175877   \n",
              "avg_wind_direction_9am   1091    142.2355107005759   69.13785928889189   \n",
              "avg_wind_speed_9am       1092     5.50828424225493  4.5528134655317185   \n",
              "max_wind_direction_9am   1092   148.95351796516923   67.23801294602953   \n",
              "max_wind_speed_9am       1091    7.019513529175272   5.598209170780958   \n",
              "rain_accumulation_9am    1089  0.20307895225211126  1.5939521253574893   \n",
              "rain_duration_9am        1092    294.1080522756142  1598.0787786601481   \n",
              "relative_humidity_9am    1095    34.24140205923536  25.472066802250055   \n",
              "relative_humidity_3pm    1095    35.34472714825898  22.524079453587273   \n",
              "\n",
              "                                         3                   4  \n",
              "summary                                min                 max  \n",
              "number                                   0                1094  \n",
              "air_pressure_9am         907.9900000000024   929.3200000000012  \n",
              "air_temp_9am            36.752000000000685   98.90599999999992  \n",
              "avg_wind_direction_9am  15.500000000000046               343.4  \n",
              "avg_wind_speed_9am        0.69345139999974  23.554978199999763  \n",
              "max_wind_direction_9am   28.89999999999991  312.19999999999993  \n",
              "max_wind_speed_9am      1.1855782000000479   29.84077959999996  \n",
              "rain_accumulation_9am                  0.0   24.01999999999907  \n",
              "rain_duration_9am                      0.0             17704.0  \n",
              "relative_humidity_9am    6.090000000001012    92.6200000000002  \n",
              "relative_humidity_3pm   5.3000000000006855    92.2500000000003  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d34831ff-5f48-436b-b3a7-463768371960\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>summary</th>\n",
              "      <td>count</td>\n",
              "      <td>mean</td>\n",
              "      <td>stddev</td>\n",
              "      <td>min</td>\n",
              "      <td>max</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>number</th>\n",
              "      <td>1095</td>\n",
              "      <td>547.0</td>\n",
              "      <td>316.24357700987383</td>\n",
              "      <td>0</td>\n",
              "      <td>1094</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>air_pressure_9am</th>\n",
              "      <td>1092</td>\n",
              "      <td>918.8825513138094</td>\n",
              "      <td>3.184161180386833</td>\n",
              "      <td>907.9900000000024</td>\n",
              "      <td>929.3200000000012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>air_temp_9am</th>\n",
              "      <td>1090</td>\n",
              "      <td>64.93300141287072</td>\n",
              "      <td>11.175514003175877</td>\n",
              "      <td>36.752000000000685</td>\n",
              "      <td>98.90599999999992</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>avg_wind_direction_9am</th>\n",
              "      <td>1091</td>\n",
              "      <td>142.2355107005759</td>\n",
              "      <td>69.13785928889189</td>\n",
              "      <td>15.500000000000046</td>\n",
              "      <td>343.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>avg_wind_speed_9am</th>\n",
              "      <td>1092</td>\n",
              "      <td>5.50828424225493</td>\n",
              "      <td>4.5528134655317185</td>\n",
              "      <td>0.69345139999974</td>\n",
              "      <td>23.554978199999763</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max_wind_direction_9am</th>\n",
              "      <td>1092</td>\n",
              "      <td>148.95351796516923</td>\n",
              "      <td>67.23801294602953</td>\n",
              "      <td>28.89999999999991</td>\n",
              "      <td>312.19999999999993</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max_wind_speed_9am</th>\n",
              "      <td>1091</td>\n",
              "      <td>7.019513529175272</td>\n",
              "      <td>5.598209170780958</td>\n",
              "      <td>1.1855782000000479</td>\n",
              "      <td>29.84077959999996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rain_accumulation_9am</th>\n",
              "      <td>1089</td>\n",
              "      <td>0.20307895225211126</td>\n",
              "      <td>1.5939521253574893</td>\n",
              "      <td>0.0</td>\n",
              "      <td>24.01999999999907</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rain_duration_9am</th>\n",
              "      <td>1092</td>\n",
              "      <td>294.1080522756142</td>\n",
              "      <td>1598.0787786601481</td>\n",
              "      <td>0.0</td>\n",
              "      <td>17704.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>relative_humidity_9am</th>\n",
              "      <td>1095</td>\n",
              "      <td>34.24140205923536</td>\n",
              "      <td>25.472066802250055</td>\n",
              "      <td>6.090000000001012</td>\n",
              "      <td>92.6200000000002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>relative_humidity_3pm</th>\n",
              "      <td>1095</td>\n",
              "      <td>35.34472714825898</td>\n",
              "      <td>22.524079453587273</td>\n",
              "      <td>5.3000000000006855</td>\n",
              "      <td>92.2500000000003</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d34831ff-5f48-436b-b3a7-463768371960')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d34831ff-5f48-436b-b3a7-463768371960 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d34831ff-5f48-436b-b3a7-463768371960');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2d3888c7-5515-4ddc-b91c-c0f3f527a492\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2d3888c7-5515-4ddc-b91c-c0f3f527a492')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2d3888c7-5515-4ddc-b91c-c0f3f527a492 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "collapsed": true,
        "id": "gNJGMGbh1eHs"
      },
      "outputs": [],
      "source": [
        "# определяем столбцы, которые далее будут использоваться в классификаторе\n",
        "featureColumns = ['air_pressure_9am','air_temp_9am','avg_wind_direction_9am','avg_wind_speed_9am',\n",
        "        'max_wind_direction_9am','max_wind_speed_9am','rain_accumulation_9am',\n",
        "        'rain_duration_9am']"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Удаление неиспользуемых и отсутствующих данных\n",
        "Столбец number не несет полезной информации, поэтому его можно удалить из датасета. Для удаления колонок из DataFrame используется метод drop, аргументами которого является одно или несколько названий колонок.\n",
        "Также удалим все строки с отсутсвующими значениями."
      ],
      "metadata": {
        "id": "JDpy-yPZMA3P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop('number')"
      ],
      "metadata": {
        "id": "UfZauU8mM_63"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.na.drop()"
      ],
      "metadata": {
        "id": "2XGLUrK8NA5w"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# проверим кол-во строк и столбцов в датафрейме\n",
        "df.count(), len(df.columns)"
      ],
      "metadata": {
        "id": "z1MJAqs1NHxv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd5ce5f0-3467-4351-ecaa-51d9a3325c52"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1064, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Создание категориальной переменной\n",
        "Чтобы указать, является ли влажность низкой, создадим категориальную переменную. Пусть если значение меньше 25%, то категориальной переменной присваивается значение 0, в противном случае категориальная переменная принимает значение 1. Категориальную переменную можно создат в виде столбца  DataFrame с помощью `Binarizer`"
      ],
      "metadata": {
        "id": "tPzzyLi0NSox"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "binarizer = Binarizer(threshold=24.99999, inputCol=\"relative_humidity_3pm\", outputCol=\"label\")\n",
        "binarizedDF = binarizer.transform(df)"
      ],
      "metadata": {
        "id": "Ol2WADnTOgNn"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Аргумент *threshold* задает пороговое значение для переменной, *inputCol* - входной столбец для чтения, *outputCol* - имя нового категориального столбца. Вторая строка применяет двоичный анализатор и создает новый DataFrame с категориальным столбцом.<br/>\n",
        "Выведем первые четыре значения нового DataFrame:"
      ],
      "metadata": {
        "id": "S4A7JnzWRdNw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "binarizedDF.select(\"relative_humidity_3pm\",\"label\").show(4)"
      ],
      "metadata": {
        "id": "73gD7PqjRRcR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89fdd0b9-a5bb-4217-d6ab-0a01fec62681"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------+-----+\n",
            "|relative_humidity_3pm|label|\n",
            "+---------------------+-----+\n",
            "|   36.160000000000494|  1.0|\n",
            "|     19.4265967985621|  0.0|\n",
            "|   14.460000000000045|  0.0|\n",
            "|   12.742547353761848|  0.0|\n",
            "+---------------------+-----+\n",
            "only showing top 4 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Проверка сбалансированности данных\n",
        "Подсчитаем количество записей в каждом классе, чтобы проверить набор данных на сбалансированность."
      ],
      "metadata": {
        "id": "W-B6TIC-ZLqA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "binarizedDF.groupBy(\"label\").count().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYQ16HVqY9dJ",
        "outputId": "719b5ab1-fcbb-4ff1-f63f-535b38743560"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+\n",
            "|label|count|\n",
            "+-----+-----+\n",
            "|  0.0|  535|\n",
            "|  1.0|  529|\n",
            "+-----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Агрегация признаков\n",
        "Объединим признаки, которые будут использоваться для составления прогноза, в один вектор, необходимый для обучения моделей в PySpark MLib. Аргумент *inputCols* задает список имен столбцов, определенных ранее, а *outputCol* - имя нового столбца. Вторая строка создает новый DataFrame с агрегированными объектами в столбце."
      ],
      "metadata": {
        "id": "N5-Z3JvaWqs7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "assembler = VectorAssembler(inputCols=featureColumns, outputCol=\"features\")\n",
        "assembled = assembler.transform(binarizedDF)"
      ],
      "metadata": {
        "id": "Bxk4jWTxM_qn"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Моделирование\n",
        "Для построения моделей Spark ML предлагает следующие группы алгоритмов:\n",
        "* [Классификация и регрессия](https://spark.apache.org/docs/latest/ml-classification-regression.html)\n",
        "* [Кластеризация](https://spark.apache.org/docs/latest/ml-clustering.html)\n",
        "* [Коллаборативная фильтрация](https://spark.apache.org/docs/latest/ml-collaborative-filtering.html)\n",
        "* [Поиск часто встречающихся шаблонов](https://spark.apache.org/docs/latest/ml-frequent-pattern-mining.html)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "MkXK1vDkcs_l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Разделение данных на обучающую и тестовую выборки\n",
        "Перед тем, как перейти к построению модели, необходимо разбить набор данных на обучающую и тестовую выборки. Для этого в Spark есть стандартный метод `randomSplit()`. Первый аргумент задает количество частей, на которые нужно разделить данные, и приблизительный размер каждой из них. В данном случае определяется два набора из 80% и 20%. Обычно начальное значение можно не указывать, но здесь используем конкретное значение, чтобы получить одно и то же дерево решений при разных запусках."
      ],
      "metadata": {
        "id": "mjX5b8Q-XLdB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(trainingData, testData) = assembled.randomSplit([0.8,0.2], seed = 13234 )"
      ],
      "metadata": {
        "id": "FpZ7HApjXdMs"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Проверим размеры полученных наборов данных."
      ],
      "metadata": {
        "id": "NGQcqADBZiLb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainingData.count(), testData.count()"
      ],
      "metadata": {
        "id": "n9pGGlOXZsKc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28ace2c1-5c4e-444d-ac3e-5e8fab403986"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(846, 218)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Создание и обучение дерева решений\n",
        "Для решения рассматриваемой задачи создадим дерево решений: аргумент *labelCol* - предсказываемый столбец (таргет), *featuresCol* задает столбец агрегированных объектов (признаки), *predictionCol* – название колонки с результатом, *maxDepth* - критерий остановки для индукции дерева на основе максимальной глубины дерева, *minInstancesPerNode* - критерий остановки для индукции дерева на основе минимального количества выборок в узле, *impurity* - мера энтропии, используемая для разделения узлов."
      ],
      "metadata": {
        "id": "qGe1RSN5Zx1S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dt = DecisionTreeClassifier(labelCol=\"label\", featuresCol=\"features\", predictionCol=\"prediction\", maxDepth=5,\n",
        "                            minInstancesPerNode=20, impurity=\"gini\")"
      ],
      "metadata": {
        "id": "b776oYvFGyVe"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Обучение дерева решений путем выполнения его в Pipeline:"
      ],
      "metadata": {
        "id": "hbUiKR2AG92u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = Pipeline(stages=[dt]) # stages определяет последовательность действий в контейнере\n",
        "model = pipeline.fit(trainingData)"
      ],
      "metadata": {
        "id": "XzrV9eCmHFWH"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Выполним прогноз, используя набор тестовых данных:"
      ],
      "metadata": {
        "id": "a3Ze8DHMHJV4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.transform(testData)"
      ],
      "metadata": {
        "id": "OU1yC5FzHQk9"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "По первым десяти строкам в прогнозе видно, что предсказание соответствует входным данным:"
      ],
      "metadata": {
        "id": "e1IWsnScHWUG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions.select(\"prediction\", \"label\").show(10)"
      ],
      "metadata": {
        "id": "24jbmpptHcFM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44f966eb-1524-4da6-fb06-b4d4f8df7bc1"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+\n",
            "|prediction|label|\n",
            "+----------+-----+\n",
            "|       1.0|  1.0|\n",
            "|       1.0|  1.0|\n",
            "|       0.0|  1.0|\n",
            "|       1.0|  1.0|\n",
            "|       1.0|  1.0|\n",
            "|       1.0|  1.0|\n",
            "|       1.0|  1.0|\n",
            "|       1.0|  1.0|\n",
            "|       0.0|  0.0|\n",
            "|       1.0|  1.0|\n",
            "+----------+-----+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Сохранение предсказания в формате CSV\n",
        "Cохраним прогнозы в CSV-файл (только столбцы *prediction* и *labe*l)."
      ],
      "metadata": {
        "id": "h0Jbe-UlHhDU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions.select(\"prediction\", \"label\").write.save(path=\"predictions.csv\",\n",
        "                                                     format=\"com.databricks.spark.csv\",\n",
        "                                                     header='true')"
      ],
      "metadata": {
        "id": "OA540lQMHzZ_"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Оценка качества модели"
      ],
      "metadata": {
        "id": "djI17BaUHPU7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Оценка качества модели\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
      ],
      "metadata": {
        "id": "kKaZb_GjTWrA"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`MulticlassClassificationEvaluator` позволяет определять различные метрики\n",
        "модели. Для этого создадим экземпляр MulticlassClassificationEvaluator.\n",
        "Первые два аргумента указывают имена столбцов меток и прогнозов, а третий аргумент указывает, что нам нужна общая точность."
      ],
      "metadata": {
        "id": "tWRTblKwVvnm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator = MulticlassClassificationEvaluator(). \\\n",
        "    setLabelCol(\"label\"). \\\n",
        "    setPredictionCol(\"prediction\"). \\\n",
        "    setMetricName(\"accuracy\")"
      ],
      "metadata": {
        "id": "m_nLtRbQWjLO"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "MNob33dU7fEF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Можно вычислить accuracy, вызвав функцию evaluate():"
      ],
      "metadata": {
        "id": "qyvSkAjIXGog"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator.evaluate(predictions)"
      ],
      "metadata": {
        "id": "5--Q4firXXDx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03aeca37-5b1c-4ae6-9a98-202c331298ef"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7844036697247706"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Отображение матрицы путаницы\n",
        "Полезным способом оценки модели является матрица ошибок:\n",
        "* True Positive (TP) – label is positive and prediction is also positive\n",
        "* True Negative (TN) – label is negative and prediction is also negative\n",
        "* False Positive (FP) – label is negative but prediction is positive\n",
        "* False Negative (FN) – label is positive but prediction is negative\n",
        "\n",
        "В Spark ML нет методов, вычисляющих матрицу ошибок непосредственно, но её легко вычислить непосредственно:"
      ],
      "metadata": {
        "id": "O0KRrkuBYeor"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tp = predictions[(predictions.label == 1) & (predictions.prediction == 1)].count()\n",
        "tn = predictions[(predictions.label == 0) & (predictions.prediction == 0)].count()\n",
        "fp = predictions[(predictions.label == 0) & (predictions.prediction == 1)].count()\n",
        "fn = predictions[(predictions.label == 1) & (predictions.prediction == 0)].count()\n",
        "\n",
        "print(\"True Positives:\", tp)\n",
        "print(\"True Negatives:\", tn)\n",
        "print(\"False Positives:\", fp)\n",
        "print(\"False Negatives:\", fn)\n",
        "print(\"Total\", predictions.count())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8i9W8pah5-p",
        "outputId": "2c24f4b1-3ddc-4fed-8092-da0ab2c01c54"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True Positives: 84\n",
            "True Negatives: 87\n",
            "False Positives: 19\n",
            "False Negatives: 28\n",
            "Total 218\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r = float(tp)/(tp + fn)\n",
        "print(\"recall\", r)\n",
        "\n",
        "p = float(tp)/(tp + fp)\n",
        "print(\"precision\", p)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCVKau5tpvVz",
        "outputId": "f314129e-ac12-450c-ecef-81a19496ebee"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "recall 0.75\n",
            "precision 0.8155339805825242\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Confusion Matrix:\\n{tp:>4}\\t{fp:>4}\\n{fn:>4}\\t{tn:>4}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06pdZtJjqXmi",
        "outputId": "e39bd915-a05d-4f63-c295-3401d85febc6"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "  84\t  19\n",
            "  28\t  87\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Желательно, чтобы значения на главной диагонали матрицы были большими, а на побочной – маленькими."
      ],
      "metadata": {
        "id": "UI0C1uCsrDjr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Оптимизация деревьев решений\n",
        "Повысить качество модели можно, подобрав гиперпараметры.\n",
        "\n",
        "#### Гиперпараметры дерева решений\n",
        "С полным списоком гиперпараметров можно ознакомиться [здесь](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html).<br/>\n",
        "Рассмотрим наиболее важные гиперпараметры:\n",
        "* Максимальная глубина (**maxDepth**) — это максимальное количество связанных решений, которые классификатор примет для классификации примера (используется для избежания переобучения).\n",
        "* Мера примеси (**impurity**) — хорошие правила делят целевые значения обучающих данных на относительно однородные или «чистые» подмножества. Выбор наилучшего правила означает минимизацию нечистоты двух подмножеств, которые оно вызывает. В основном используются две меры примеси: gini и entropy.\n",
        "* Минимальный информационный прирост (**minInfoGain**) — это гиперпараметр, который определяет минимальный информационный прирост или уменьшение примесей для правил принятия решений‑кандидатов.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "IWynjbXnbHn1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Реализация\n",
        "Для начала необходимо создать стандартный контейнер аналогично рассмотренному выше."
      ],
      "metadata": {
        "id": "1-CvFO-qehH-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Аналогично предыдущему разделу создаём pipeline\n",
        "pipeline_with_optimization = pipeline"
      ],
      "metadata": {
        "id": "hgsZs1QEe1nt"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Затем в `ParamGridBuilder` определяем возможные варианты интересующих гиперпараметров:"
      ],
      "metadata": {
        "id": "DCx9sxd3fEll"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Определяю гиперпараметры\n",
        "from pyspark.ml.tuning import ParamGridBuilder\n",
        "\n",
        "paramGrid_with_optimization = ParamGridBuilder(). \\\n",
        "    addGrid(dt.impurity, [\"gini\", \"entropy\"]). \\\n",
        "    addGrid(dt.maxDepth, [5, 8, 10]). \\\n",
        "    addGrid(dt.maxBins, [20, 30]). \\\n",
        "    addGrid(dt.minInfoGain, [0.0]). \\\n",
        "    build()\n",
        "\n",
        "# impurity - Примесь\n",
        "# maxDepth - Максимальная глубина дерева\n",
        "# maxBins - Максимальное количество бинов (развилок) в дереве\n",
        "# minInfoGain- Минимальный прирост информации"
      ],
      "metadata": {
        "id": "ewqCDaNafNj8"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Далее передаем в `TrainValidationSplit` правила построения модели (pipeline_with_optimization), метрику сравнения моделей (multiclassEval), возможные варианты гиперпараметров (paramGrid_with_optimization) и соотношение, на которое разобьётся train (trainRatio), т.е. dataset train во время обучения поделится на две выборки: на одной модели будут обучаться, а с помощью второй модели будут сравниваться между собой."
      ],
      "metadata": {
        "id": "DCFAOTykf4xL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Построение модели для поиска оптимального варианта\n",
        "from pyspark.ml.tuning import TrainValidationSplit\n",
        "\n",
        "# estimator - контейнер с логикой построения модели\n",
        "# evaluator - метрика для сравнения моделей\n",
        "# estimatorParamMaps - варьируемые гиперпараметры\n",
        "# trainRatio - соотношением для разбивки выборки train во время обучения\n",
        "\n",
        "validator = TrainValidationSplit(seed=1234, estimator=pipeline_with_optimization, evaluator=MulticlassClassificationEvaluator(), estimatorParamMaps=paramGrid_with_optimization, trainRatio=0.9)\n",
        "model_with_optimization = validator.fit(trainingData)"
      ],
      "metadata": {
        "id": "gv5_9OqPgDNd"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Можно посмотреть результаты работы каждой модели, а также их гиперпараметры."
      ],
      "metadata": {
        "id": "L3sqg8BBg7Qu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = model_with_optimization.validationMetrics #оценки\n",
        "params = model_with_optimization.getEstimatorParamMaps() #гиперпараметры\n",
        "metrics_and_params = list(zip(metrics, params))\n",
        "metrics_and_params.sort(key=lambda x: x[0], reverse=True)\n",
        "\n",
        "metrics_and_params"
      ],
      "metadata": {
        "id": "74qaTOBrhGc6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b64b654f-2cf5-418b-d0e9-8fe77389dca4"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0.7681197412063686,\n",
              "  {Param(parent='DecisionTreeClassifier_e111fb162418', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
              "   Param(parent='DecisionTreeClassifier_e111fb162418', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 5,\n",
              "   Param(parent='DecisionTreeClassifier_e111fb162418', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 30,\n",
              "   Param(parent='DecisionTreeClassifier_e111fb162418', name='minInfoGain', doc='Minimum information gain for a split to be considered at a tree node.'): 0.0}),\n",
              " (0.7681197412063686,\n",
              "  {Param(parent='DecisionTreeClassifier_e111fb162418', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'entropy',\n",
              "   Param(parent='DecisionTreeClassifier_e111fb162418', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 5,\n",
              "   Param(parent='DecisionTreeClassifier_e111fb162418', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 30,\n",
              "   Param(parent='DecisionTreeClassifier_e111fb162418', name='minInfoGain', doc='Minimum information gain for a split to be considered at a tree node.'): 0.0}),\n",
              " (0.7440168534224434,\n",
              "  {Param(parent='DecisionTreeClassifier_e111fb162418', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
              "   Param(parent='DecisionTreeClassifier_e111fb162418', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 8,\n",
              "   Param(parent='DecisionTreeClassifier_e111fb162418', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 30,\n",
              "   Param(parent='DecisionTreeClassifier_e111fb162418', name='minInfoGain', doc='Minimum information gain for a split to be considered at a tree node.'): 0.0}),\n",
              " (0.7440168534224434,\n",
              "  {Param(parent='DecisionTreeClassifier_e111fb162418', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
              "   Param(parent='DecisionTreeClassifier_e111fb162418', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 10,\n",
              "   Param(parent='DecisionTreeClassifier_e111fb162418', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 30,\n",
              "   Param(parent='DecisionTreeClassifier_e111fb162418', name='minInfoGain', doc='Minimum information gain for a split to be considered at a tree node.'): 0.0}),\n",
              " (0.7440168534224434,\n",
              "  {Param(parent='DecisionTreeClassifier_e111fb162418', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'entropy',\n",
              "   Param(parent='DecisionTreeClassifier_e111fb162418', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 8,\n",
              "   Param(parent='DecisionTreeClassifier_e111fb162418', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 30,\n",
              "   Param(parent='DecisionTreeClassifier_e111fb162418', name='minInfoGain', doc='Minimum information gain for a split to be considered at a tree node.'): 0.0}),\n",
              " (0.7440168534224434,\n",
              "  {Param(parent='DecisionTreeClassifier_e111fb162418', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'entropy',\n",
              "   Param(parent='DecisionTreeClassifier_e111fb162418', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 10,\n",
              "   Param(parent='DecisionTreeClassifier_e111fb162418', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 30,\n",
              "   Param(parent='DecisionTreeClassifier_e111fb162418', name='minInfoGain', doc='Minimum information gain for a split to be considered at a tree node.'): 0.0}),\n",
              " (0.7312282229965157,\n",
              "  {Param(parent='DecisionTreeClassifier_e111fb162418', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
              "   Param(parent='DecisionTreeClassifier_e111fb162418', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 5,\n",
              "   Param(parent='DecisionTreeClassifier_e111fb162418', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 20,\n",
              "   Param(parent='DecisionTreeClassifier_e111fb162418', name='minInfoGain', doc='Minimum information gain for a split to be considered at a tree node.'): 0.0}),\n",
              " (0.7059208516951001,\n",
              "  {Param(parent='DecisionTreeClassifier_e111fb162418', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
              "   Param(parent='DecisionTreeClassifier_e111fb162418', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 8,\n",
              "   Param(parent='DecisionTreeClassifier_e111fb162418', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 20,\n",
              "   Param(parent='DecisionTreeClassifier_e111fb162418', name='minInfoGain', doc='Minimum information gain for a split to be considered at a tree node.'): 0.0}),\n",
              " (0.7059208516951001,\n",
              "  {Param(parent='DecisionTreeClassifier_e111fb162418', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
              "   Param(parent='DecisionTreeClassifier_e111fb162418', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 10,\n",
              "   Param(parent='DecisionTreeClassifier_e111fb162418', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 20,\n",
              "   Param(parent='DecisionTreeClassifier_e111fb162418', name='minInfoGain', doc='Minimum information gain for a split to be considered at a tree node.'): 0.0}),\n",
              " (0.6685198737343396,\n",
              "  {Param(parent='DecisionTreeClassifier_e111fb162418', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'entropy',\n",
              "   Param(parent='DecisionTreeClassifier_e111fb162418', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 8,\n",
              "   Param(parent='DecisionTreeClassifier_e111fb162418', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 20,\n",
              "   Param(parent='DecisionTreeClassifier_e111fb162418', name='minInfoGain', doc='Minimum information gain for a split to be considered at a tree node.'): 0.0}),\n",
              " (0.6685198737343396,\n",
              "  {Param(parent='DecisionTreeClassifier_e111fb162418', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'entropy',\n",
              "   Param(parent='DecisionTreeClassifier_e111fb162418', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 10,\n",
              "   Param(parent='DecisionTreeClassifier_e111fb162418', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 20,\n",
              "   Param(parent='DecisionTreeClassifier_e111fb162418', name='minInfoGain', doc='Minimum information gain for a split to be considered at a tree node.'): 0.0}),\n",
              " (0.6669334064127158,\n",
              "  {Param(parent='DecisionTreeClassifier_e111fb162418', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'entropy',\n",
              "   Param(parent='DecisionTreeClassifier_e111fb162418', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 5,\n",
              "   Param(parent='DecisionTreeClassifier_e111fb162418', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 20,\n",
              "   Param(parent='DecisionTreeClassifier_e111fb162418', name='minInfoGain', doc='Minimum information gain for a split to be considered at a tree node.'): 0.0})]"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "С помощью метода `bestModel` «вытаскиваем» лучшую модель из набора."
      ],
      "metadata": {
        "id": "zQlgZ_GXhOmA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Результат лучшей модели на тестовой выборке\n",
        "predictions = model_with_optimization.transform(testData)\n",
        "\n",
        "predictions.select(\"features\", \"label\", \"prediction\").show()\n"
      ],
      "metadata": {
        "id": "riSg6WBrhSs9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48acc75b-387c-4bcf-c066-b44bda3d009c"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----+----------+\n",
            "|            features|label|prediction|\n",
            "+--------------------+-----+----------+\n",
            "|[911.270000000013...|  1.0|       1.0|\n",
            "|[912.300000000012...|  1.0|       0.0|\n",
            "|[912.410000000007...|  1.0|       0.0|\n",
            "|[912.600000000005...|  1.0|       1.0|\n",
            "|[912.790000000002...|  1.0|       1.0|\n",
            "|[912.800000000002...|  1.0|       1.0|\n",
            "|[913.200000000008...|  1.0|       1.0|\n",
            "|[913.260000000007...|  1.0|       1.0|\n",
            "|[913.320000000003...|  0.0|       0.0|\n",
            "|[913.490000000008...|  1.0|       1.0|\n",
            "|[913.520000000012...|  1.0|       1.0|\n",
            "|[914.060000000007...|  1.0|       1.0|\n",
            "|[914.070000000001...|  1.0|       1.0|\n",
            "|[914.154388930716...|  0.0|       0.0|\n",
            "|[914.300000000007...|  1.0|       1.0|\n",
            "|[914.360000000011...|  1.0|       1.0|\n",
            "|[914.400000000012...|  1.0|       1.0|\n",
            "|[914.460000000007...|  1.0|       0.0|\n",
            "|[914.560000000013...|  1.0|       1.0|\n",
            "|[914.600000000007...|  1.0|       1.0|\n",
            "+--------------------+-----+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator.evaluate(predictions.select(\"features\", \"label\", \"prediction\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bHUai-ibStz",
        "outputId": "a276a972-aef4-4e0d-9983-f48f43d29b6e"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7706422018348624"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Случайные леса решений\n",
        "Точность прогноза можно ьакже повысить, используя не одно дерево, а много деревьев, каждое из которых дает разумные, но разные и независимые оценки правильного целевого значения. Их коллективный средний прогноз должен быть близок к истинному ответу больше, чем прогноз любого отдельного дерева. Это есть алгоритм *случайного леса*.\n",
        "\n",
        "Предсказание случайного леса — это просто средневзвешенное значение предсказаний отдельных деревьев. Для категориальной цели это может быть большинство голосов или наиболее вероятное значение, основанное на среднем значении вероятностей, полученных деревьями. Случайные леса, как и деревья решений, также поддерживают регрессию, и прогноз леса в этом случае представляет собой среднее число, предсказанное каждым деревом.\n",
        "\n",
        "Хотя случайные леса являются более мощным и сложным методом классификации, разработка модели практически ничем не отличается от разработки дерева."
      ],
      "metadata": {
        "id": "0J9_G5iBhopO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сначала заменим в stages модель дерева на модель случайного леса:\n"
      ],
      "metadata": {
        "id": "sNq4wSMYihFy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "\n",
        "# Поменяем модель с дерева на лес\n",
        "classifier_forest = RandomForestClassifier().setLabelCol(\"label\").setFeaturesCol(\"features\").setPredictionCol(\"prediction\")\n",
        "\n",
        "pipeline_forest = Pipeline(stages=[classifier_forest])\n",
        "model = pipeline_forest.fit(trainingData)"
      ],
      "metadata": {
        "id": "ztGPjb1VitGg"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Добавим еще один гиперпараметр: numTrees – количество деревьев в лесе."
      ],
      "metadata": {
        "id": "coWHo-4c0gjZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "paramGrid_forest = ParamGridBuilder(). \\\n",
        "    addGrid(classifier_forest.impurity, [\"gini\"]). \\\n",
        "    addGrid(classifier_forest.maxDepth, [5]). \\\n",
        "    addGrid(classifier_forest.maxBins, [20]). \\\n",
        "    addGrid(classifier_forest.minInfoGain, [0.0]). \\\n",
        "    addGrid(classifier_forest.numTrees, [2, 4, 6]). \\\n",
        "    build()"
      ],
      "metadata": {
        "id": "9ENmQDHw0m9U"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Аналогично предыдущему разделу тренируем модели и извлекаю наилучшую:"
      ],
      "metadata": {
        "id": "QUA-S28h0uL1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Построение модели для поиска оптимального варианта\n",
        "validator = TrainValidationSplit(seed=1234, estimator=pipeline_forest, evaluator=MulticlassClassificationEvaluator(), estimatorParamMaps=paramGrid_forest, trainRatio=0.8)\n",
        "model_forest = validator.fit(trainingData)\n",
        "\n",
        "# Извлекаем RandomForestClassifier() из PipelineModel\n",
        "predictions = model_forest.transform(testData)\n",
        "\n",
        "predictions.select(\"features\", \"label\", \"prediction\").show()"
      ],
      "metadata": {
        "id": "CHjrMHcQ0w2A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4de68f8-7d8b-4568-cd80-a96db3ff13ba"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----+----------+\n",
            "|            features|label|prediction|\n",
            "+--------------------+-----+----------+\n",
            "|[911.270000000013...|  1.0|       1.0|\n",
            "|[912.300000000012...|  1.0|       0.0|\n",
            "|[912.410000000007...|  1.0|       1.0|\n",
            "|[912.600000000005...|  1.0|       1.0|\n",
            "|[912.790000000002...|  1.0|       1.0|\n",
            "|[912.800000000002...|  1.0|       1.0|\n",
            "|[913.200000000008...|  1.0|       1.0|\n",
            "|[913.260000000007...|  1.0|       1.0|\n",
            "|[913.320000000003...|  0.0|       0.0|\n",
            "|[913.490000000008...|  1.0|       1.0|\n",
            "|[913.520000000012...|  1.0|       1.0|\n",
            "|[914.060000000007...|  1.0|       1.0|\n",
            "|[914.070000000001...|  1.0|       1.0|\n",
            "|[914.154388930716...|  0.0|       0.0|\n",
            "|[914.300000000007...|  1.0|       1.0|\n",
            "|[914.360000000011...|  1.0|       1.0|\n",
            "|[914.400000000012...|  1.0|       0.0|\n",
            "|[914.460000000007...|  1.0|       0.0|\n",
            "|[914.560000000013...|  1.0|       1.0|\n",
            "|[914.600000000007...|  1.0|       1.0|\n",
            "+--------------------+-----+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator.evaluate(predictions.select(\"features\", \"label\", \"prediction\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wdCu6FFxbFUT",
        "outputId": "c0327903-4a4d-4baa-fded-9460c6d66d4b"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7889908256880734"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Переход от string к integer\n",
        "\n"
      ],
      "metadata": {
        "id": "4lcZzsCMs1QC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Использование udf функции\n",
        "Использование таких функций позволяет работать с sparkDataframe, как с pandasDataframe, но без использования `toPandas()`, что позволяет сэкономить время.\n",
        "\n",
        "```\n",
        "# Перевод двух столбцов (month и y) из типа string в тип integer\n",
        "\n",
        "# Создаем udf функции с правилами перевода\n",
        "\"\"\"Transforms yes/no to digit 1/0\"\"\"\n",
        "@F.pandas_udf(T.IntegerType())\n",
        "def y_to_digit(y: pd.Series) -> pd.Series:\n",
        "    return (y == 'yes')\n",
        "\n",
        "\"\"\"Transforms months to digit\"\"\"\n",
        "@F.pandas_udf(T.IntegerType())\n",
        "def month_to_digit(month: pd.Series) -> pd.Series:\n",
        "    months = {'jan': 1, 'feb': 2, 'mar': 3, 'apr': 4, 'may': 5, 'jun': 6, 'jul': 7, 'aug': 8, 'sep': 9, 'oct': 10, 'nov': 11, 'dec': 12}\n",
        "    return month.map(months)\n",
        "\n",
        "# Трансформируем столбцы по правилам перевода\n",
        "data_after_udf = data_raw.withColumn('y', y_to_digit(F.col('y'))).withColumn('month', month_to_digit(F.col('month')))\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "GqSvNFq6azEm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. OneHotEncoder или преобразование в бинарные вектора\n",
        "```\n",
        "# Преобразование категориальных колонок в бинарные вектора\n",
        "categoricalColumns = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'poutcome']\n",
        "for categoricalCol in categoricalColumns:\n",
        "    stringIndexer = StringIndexer(inputCol = categoricalCol, outputCol = categoricalCol + 'Index', handleInvalid = 'keep')\n",
        "    encoder = OneHotEncoder(inputCol = stringIndexer.getOutputCol(), outputCol = categoricalCol + \"classVec\")\n",
        "    stages += [stringIndexer, encoder]\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "sDPh3v4IzgFv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradient-Boosted Trees\n",
        "\n",
        "s"
      ],
      "metadata": {
        "id": "SHIdGVrO4l-9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import GBTClassifier\n",
        "\n",
        "gbt_classifier = GBTClassifier().setLabelCol(\"label\").setFeaturesCol(\"features\").setPredictionCol(\"prediction\")\n",
        "\n",
        "pipeline_gbt = Pipeline(stages=[gbt_classifier])\n",
        "#model = pipeline_gbt.fit(trainingData)"
      ],
      "metadata": {
        "id": "0tIWKjZh6ugY"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "paramGrid_GBT = ParamGridBuilder(). \\\n",
        "    addGrid(gbt_classifier.impurity, [\"variance\"]). \\\n",
        "    addGrid(gbt_classifier.maxDepth, [5, 15, 25]). \\\n",
        "    addGrid(gbt_classifier.maxBins, [20, 30]). \\\n",
        "    addGrid(gbt_classifier.minInfoGain, [0.0]). \\\n",
        "    addGrid(gbt_classifier.lossType , [\"logistic\"]). \\\n",
        "    addGrid(gbt_classifier.maxIter , [10, 25, 50]). \\\n",
        "    addGrid(gbt_classifier.featureSubsetStrategy  , [\"auto\", \"all\"]). \\\n",
        "    build()"
      ],
      "metadata": {
        "id": "r7j3I0vHBQFs"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Построение модели для поиска оптимального варианта\n",
        "validator = TrainValidationSplit(seed=1234, estimator=pipeline_gbt, evaluator=MulticlassClassificationEvaluator(), estimatorParamMaps=paramGrid_GBT, trainRatio=0.8)\n",
        "model_gbt = validator.fit(trainingData)\n",
        "\n",
        "# Извлекаем RandomForestClassifier() из PipelineModel\n",
        "predictions = model_gbt.transform(testData)\n",
        "\n",
        "predictions.select(\"features\", \"label\", \"prediction\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXq2lL8pGhAQ",
        "outputId": "a86d05a2-06cd-453f-f98f-a4cd3ea04b13"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----+----------+\n",
            "|            features|label|prediction|\n",
            "+--------------------+-----+----------+\n",
            "|[911.270000000013...|  1.0|       1.0|\n",
            "|[912.300000000012...|  1.0|       1.0|\n",
            "|[912.410000000007...|  1.0|       1.0|\n",
            "|[912.600000000005...|  1.0|       1.0|\n",
            "|[912.790000000002...|  1.0|       1.0|\n",
            "|[912.800000000002...|  1.0|       1.0|\n",
            "|[913.200000000008...|  1.0|       1.0|\n",
            "|[913.260000000007...|  1.0|       1.0|\n",
            "|[913.320000000003...|  0.0|       0.0|\n",
            "|[913.490000000008...|  1.0|       1.0|\n",
            "|[913.520000000012...|  1.0|       1.0|\n",
            "|[914.060000000007...|  1.0|       1.0|\n",
            "|[914.070000000001...|  1.0|       1.0|\n",
            "|[914.154388930716...|  0.0|       0.0|\n",
            "|[914.300000000007...|  1.0|       1.0|\n",
            "|[914.360000000011...|  1.0|       1.0|\n",
            "|[914.400000000012...|  1.0|       0.0|\n",
            "|[914.460000000007...|  1.0|       0.0|\n",
            "|[914.560000000013...|  1.0|       1.0|\n",
            "|[914.600000000007...|  1.0|       1.0|\n",
            "+--------------------+-----+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator.evaluate(predictions.select(\"features\", \"label\", \"prediction\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yte9FrZxT-iB",
        "outputId": "e2acc086-b580-4516-a6c3-e24beeb03bd6"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8302752293577982"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    }
  ]
}